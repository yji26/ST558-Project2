---
title: "ST 558 - Summer 2020 - Project 2"
author: "Yun Ji"
date: "7/3/2020"
output:
  rmarkdown::github_document:
    toc: true
params:
  day: ""
---

## Data Set Information
The data set used in this project consists of 58 numerical predictor variables along with 2 informational fields; the target for the data set is the column `shares`, a measure of an article's popularity.

Seven columns from the data set are indicator values for the day of week that an article is published; these columns are named `weekday_is_monday`, `weekday_is_tuesday`, etc. For each weekday, I shall create a separate set of models to predict the `shares` value. The follow code will load the data set, filter on a specific day of week, then split the resulting data 70/30 into training and testing data sets. The training set will be used for training the linear and non-linear regression models, and the testing set for comparing which of the models has a higher prediction accuracy.

```{r load news data}
newsData <- read_csv("./Data/OnlineNewsPopularity.csv")
```

Some columns can be removed to reduce the size of the data. Column `url` merely contains the text URL for the article and is not needed. Column `timedelta` represents the number of days between article publication and data acquisition; although this can potentially be used to detect the site's popularity over time, the data dictionary describes this as non-predictive data and therefore I will also exclude it from the modeling data. Column `is_weekend` is made redundant when the data is split by day of week, since for any given day the column value will be either all zeroes or all ones. Columns `rate_positive_words` and `rate_negative_words` represent the proportion of positive and negative words among all non-neutral words, and always sum to 1; therefore, one of these columns can be removed without any loss of information, and I choose to remove `rate_negative_words`.

```{r remove columns}
newsData <- newsData %>%
  select(!url & !timedelta & !is_weekend & !rate_negative_words)
```

## Filter for `r params$day` Data
Next I filter for the day of week, then remove the `weekday_is_*` columns.

```{r day of week filtering}
dayOfWeek <- params$day
dayColumn <- paste0("weekday_is_", tolower(dayOfWeek))

newsDataFiltered <- newsData %>%
  filter((!!as.symbol(dayColumn)) == 1) %>%
  select(!starts_with("weekday_is_"))
```

Finally I split the resulting data into training and testing sets.

```{r train test split}
set.seed(seed)
train <- sample(1:nrow(newsDataFiltered), size = nrow(newsDataFiltered)*0.7)
test <- dplyr::setdiff(1:nrow(newsDataFiltered), train)
newsDataTrain <- newsDataFiltered[train, ]
newsDataTest <- newsDataFiltered[test, ]
```

## Summary of Training Data
The training data will not be the same from one day of week to another, but certain observations hold across all.

First, we can examine the distribution of the target variable `shares`.

```{r shares histogram}
g <- ggplot(data = newsDataTrain, aes(x = shares))
g + geom_histogram(bins = 50)
```

Values of `shares` appear to follow a power-law distribution where a few very popular articles receive an outsized share of views. Therefore for regression it may be better to transform the target variable using a logarithmic function.

```{r target transformation}
newsDataTrain <- newsDataTrain %>%
  mutate(shares = log10(shares))

newsDataTest <- newsDataTest %>%
  mutate(shares = log10(shares))

g <- ggplot(data = newsDataTrain, aes(x = shares))
g + geom_histogram(bins = 50)
```

The range of values for the predictor columns vary: some columns such as `global_subjectivity` are proportions and are limited to values between 0 and 1, some indicator values like `data_channel_is_world` only have values 0 or 1, and others like `n_tokens_content` are raw counts which are natural numbers with no theoretical upper bound.

```{r predictor histograms}
g <- ggplot(data = newsDataTrain, aes(x = global_subjectivity))
g + geom_histogram(bins = 10)

g <- ggplot(data = newsDataTrain, aes(x = data_channel_is_world))
g + geom_histogram(bins = 2)

g <- ggplot(data = newsDataTrain, aes(x = n_tokens_content))
g + geom_histogram(bins = 50)
```

Because of this, when selecting for models, it is advised to standardize (that is, center and scale) predictor values prior to fitting the models.

